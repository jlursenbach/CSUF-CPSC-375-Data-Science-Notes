# Final Review

HW solutions

[CPSC 375 Summer 2022 Homework 1 Solutions.docx](Final%20Review%204fbf16bb3cb04c1c968f23bc5d0f6cd4/CPSC_375_Summer_2022_Homework_1_Solutions.docx)

[CPSC 375 Summer 2022 Homework 2 solutions.docx](Final%20Review%204fbf16bb3cb04c1c968f23bc5d0f6cd4/CPSC_375_Summer_2022_Homework_2_solutions.docx)

[CPSC 375 Summer 2022 Homework 3 solution.docx](Final%20Review%204fbf16bb3cb04c1c968f23bc5d0f6cd4/CPSC_375_Summer_2022_Homework_3_solution.docx)

[CPSC 375 Summer 2022 Homework 4 Solutions.docx](Final%20Review%204fbf16bb3cb04c1c968f23bc5d0f6cd4/CPSC_375_Summer_2022_Homework_4_Solutions.docx)

[CPSC 375 Summer 2022 Homework 5 solutions.docx](Final%20Review%204fbf16bb3cb04c1c968f23bc5d0f6cd4/CPSC_375_Summer_2022_Homework_5_solutions.docx)

Final Exam Study Guide

[CPSC 375 Summer 2022 Final Exam Study Guide.docx](Final%20Review%204fbf16bb3cb04c1c968f23bc5d0f6cd4/CPSC_375_Summer_2022_Final_Exam_Study_Guide.docx)

# CPSC 375 Final Exam Study Guide

# Summer 2022

The final exam will take place online on Canvas, similar to the midterm on:

**Wednesday, June 29, 2:30-4:30pm.** (You do not have to be on Zoom; I will be in the classroom and on Zoom however if you have any clarifying questions.) It will cover the material **not** covered in the midterm. The exam is open-notes (including class powerpoint slides and code postings) and open textbook. No Internet access is allowed other than to access the online textbook and Canvas. The best way to prepare for the exam is going through the homework and classwork assignments.

The hour before the exam on 6/29 will be a **review session**. Please be prepared to ask questions based on this study guide.

The following material is fair game:

1. K-nearest neighbors (k-nn)
    1. Concept of supervised learning: test/train data
    2. The k-nn algorithm
    3. How to determine k
    4. Advantages and disadvantages of k-nn
2. Distance metrics
    1. Euclidean distance
        
        ![Untitled](Final%20Review%204fbf16bb3cb04c1c968f23bc5d0f6cd4/Untitled.png)
        
    2. Manhattan distance
        
        ![Untitled](Final%20Review%204fbf16bb3cb04c1c968f23bc5d0f6cd4/Untitled%201.png)
        
    3. Jaccard similarity
        
        ![Untitled](Final%20Review%204fbf16bb3cb04c1c968f23bc5d0f6cd4/Untitled%202.png)
        
        ![Untitled](Final%20Review%204fbf16bb3cb04c1c968f23bc5d0f6cd4/Untitled%203.png)
        
3. Evaluation metrics
    1. Confusion matrix: true/false positives/negatives
    2. Accuracy, error
    3. Precision, recall, f-measure
4. Clustering
    1. The k-means algorithm
        1. How to calculate the center of a cluster
        2. How to assign points to a centroid
    2. How to choose initial centers (seeds)
        1. Random
        2. Furthest centers heuristics
    3. Advantages and disadvantages of k-means
5. Time series analysis
    1. Time-series classification
        1. Inadequacy of Euclidean distance
        2. Dynamic Time Warping (DTW) distance
        3. Algorithm to compute DTW
        4. Showing the optimal alignment between two time-series
6. Text processing
    1. Vector space/Bag-of-words model
    2. Term-document matrix
        1. Term frequency (Tf) weighting
        2. Inverse document frequency (Idf) weighting
        3. Tf-idf weighting
    3. Common processing steps - concepts of:
        1. Change case
        2. Stop words
        3. Word stemming
    4. Cosine similarity
        
        ![Untitled](Final%20Review%204fbf16bb3cb04c1c968f23bc5d0f6cd4/Untitled%204.png)
        
        normalize a vector:
        
        ![Untitled](Final%20Review%204fbf16bb3cb04c1c968f23bc5d0f6cd4/Untitled%205.png)
        
        ![Untitled](Final%20Review%204fbf16bb3cb04c1c968f23bc5d0f6cd4/Untitled%206.png)